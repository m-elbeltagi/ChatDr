{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e24435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8408bb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setting device as GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Device in use: {} \\n'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83e49a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "## loading local weights for model\n",
    "ChatDr1 = GPT2LMHeadModel.from_pretrained(r'.\\gpt2_finetune_ckpts').to(device)\n",
    "\n",
    "## max number of new generated tokens by the model\n",
    "NEW_TOKENS = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8e1d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text1(prompt):\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt')['input_ids'].to(device)\n",
    "    outputs = ChatDr1.generate(input_ids, max_new_tokens=NEW_TOKENS, do_sample=False, no_repeat_ngram_size=2,\n",
    "                              temperature=0.5, top_p=0.9, pad_token_id=tokenizer.eos_token_id)\n",
    "    print (tokenizer.decode(outputs[0]))\n",
    "    \n",
    "    \n",
    "def generate_text2(prompt):\n",
    "    outputs = ChatDr2(prompt, max_length = NEW_TOKENS)\n",
    "    print (outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "812548f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel sick  ________ here. I feel like I'm to be treated for my arthritis. It hurts a lot. But I think it's important to understand that this is not just a medical problem, this actually is a social problem. it is affecting people in many ways. it has been affecting my husband., it was affecting me in the past. but it really has not been., I am here because I believe in healing and helping people.,soap / chart / progress notes, arthritis, social, healing, swelling, pain, treatment, medicine, symptoms, sick, status, therapy, elixir, rick, tony, osteoporosis, physical, inflammation, joints, people, cure, disease, condition, etc.NOTE,: Thesetranscribed medical transcription sample reports and examples are provided by various users andare for reference purpose only. MTHelpLine does not certify accuracy and quality of sample report.These transcribed medical examples may include some uncommon or unusual formats;this would be due to the preference of the dictating physician. All names and dates have beenchanged (or removed) to keep confidentiality. Any resemblance of any type of name or date orplace or anything else to real world is purely incidental\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "generate_text1('I feel sick  ')\n",
    "print ('==========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9033b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
